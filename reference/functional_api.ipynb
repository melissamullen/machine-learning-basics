{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Input and Output: Multiclass Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Create a simple model.\n",
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "\n",
    "# Instantiate the model by specifying the inputs and outputs.\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Inputs and Outputs: Customer Support Tickets Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "# Create a model with multiple inputs and outputs.\n",
    "# Inputs: title of the ticket, text body of the ticket, and any tags added by the user\n",
    "# Outputs: priority score and department assigned\n",
    "\n",
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "# Define our input layers\n",
    "title = keras.Input(\n",
    "    shape=(vocabulary_size,), name=\"title\"\n",
    ")  # Variable-length sequence of ints\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"body\")  # Variable-length sequence of ints\n",
    "tags = keras.Input(\n",
    "    shape=(num_tags,), name=\"tags\"\n",
    ")  # Binary vectors of size `num_tags`\n",
    "\n",
    "# Concatenate inputs into a single feature vector\n",
    "features = layers.Concatenate()(\n",
    "    [title, text_body, tags]\n",
    ")  # Features are concatenated\n",
    "features = layers.Dense(64, activation=\"relu\")(features) # Project to 64-dimensions for a richer representation\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(num_departments, activation=\"softmax\", name=\"department\")(\n",
    "    features\n",
    ")\n",
    "\n",
    "# Now we define the model we will train\n",
    "model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department],\n",
    ")\n",
    "\n",
    "# Compile the model with losses and metrics\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "    metrics=[[\"mean_absolute_error\"], [\"accuracy\"]],\n",
    ")\n",
    "\n",
    "# Train the model by passing lists of NumPy arrays of inputs and targets\n",
    "# since we have multiple inputs and outputs\n",
    "\n",
    "num_samples = 1280\n",
    "title_data = np.random.randint(\n",
    "    0, 2, size=(num_samples, vocabulary_size)\n",
    ")  # Dummy title data\n",
    "\n",
    "body_data = np.random.randint(\n",
    "    0, 2, size=(num_samples, vocabulary_size)\n",
    ")  # Dummy body data\n",
    "\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags)).astype(\"float32\")  # Dummy tags data\n",
    "priority_data = np.random.random(size=(num_samples, 1))  # Dummy priority data\n",
    "department_data = np.random.randint(\n",
    "    0, 2, size=(num_samples, num_departments)\n",
    ")  # Dummy department data\n",
    "\n",
    "model.fit(\n",
    "    {\"title\": title_data, \"body\": body_data, \"tags\": tags_data},\n",
    "    {\"priority\": priority_data, \"department\": department_data},\n",
    "    epochs=2,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "model.evaluate(\n",
    "    {\"title\": title_data, \"body\": body_data, \"tags\": tags_data},\n",
    "    {\"priority\": priority_data, \"department\": department_data},\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "model.predict(\n",
    "    {\"title\": title_data, \"body\": body_data, \"tags\": tags_data},\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Feature Extraction to Create a New Model: Reusing Intermediate Layer Outputs Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model by reusing intermediate layer outputs\n",
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(1, activation=\"sigmoid\", name=\"difficulty\")(features)\n",
    "new_model = keras.Model(\n",
    "    inputs=model.inputs, outputs=[model.outputs[0], difficulty]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
